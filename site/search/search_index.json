{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Applied Nonlinear Perron-Frobenius Theory SIAM LA and ILAS 21 Conferences Tutorial Welcome to the webpage dedicated to the SIAM minitutorial on Applied Nonlinear Perron-Frobenius Theory . The page is developed and maintained by Antoine Gautier and Francesco Tudisco . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#applied_nonlinear_perron-frobenius_theory","text":"","title":"Applied Nonlinear Perron-Frobenius Theory"},{"location":"#siam_la_and_ilas_21_conferences_tutorial","text":"Welcome to the webpage dedicated to the SIAM minitutorial on Applied Nonlinear Perron-Frobenius Theory . The page is developed and maintained by Antoine Gautier and Francesco Tudisco .","title":"SIAM LA and ILAS 21 Conferences Tutorial"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project_layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"centrality/","text":"Network centrality Ranking the nodes of a network according to suitable \u201ccentrality measures\u201d is a recurring and fundamental question in network science and data mining. Among the various network centrality models, the class of eigenvector centrality is one of the most widely used and effective. This family of models dates back to chess tournaments in the 19th Century by Edmund Landau 1 and was then popularized in the network science community starting from the late \u201980s with Bonacich 2 , PageRank 3 and HITS 4 models. This class of scores assigns importances are based on the leading eigenvector \\(x\\) (or the leading singular vectors \\(x,y\\) ) of suitable network matrices and strongly rely on the matrix Perron-Frobenius theorem. One of the keys of the success of eigenvector centralities is that they naturally incorporate mutual reinforcement : important objects are those that interact with many other important objects. For example, when \\(G=(V,E)\\) is a graph with adjacency matrix \\(A\\) , Bonacich centrality model defines the importance \\(x_i\\) of node \\(i\\in V\\) as \\[ x_i\\propto \\sum_{j: \\, ij\\in E} A_{ij} \\, x_j\\, , \\] that is, the importance of node \\(x_i\\) is linearly proportional to the importances \\(x_j\\) of the nodes it shares an edge with. The Perron-Frobenius theory teaches us that only one such vector \\(x\\) exists: the Perron eigenvector of the adjacency matrix \\(Ax=\\rho(A)x\\) . Higher-order network models While graph and networks are ubiquitous in the natural sciences, in many real-world applications we are confronted with higher-order interaction data. Relational data is full of interactions that happen in groups. For example, friendship relations very often happen in groups that are strictly larger than two individuals. Moreover, interactions naturally occur on multiple layers, for example work relations, sport relations, friendship relations, etc. To model higher-order interactions we need higher-order network models, which include multilayer networks , where we have a set of networks (so-called layers) with connections internally and across the layers, and non-dyadic networks , such as hypergraphs or simplicial complexes, where we have access to interactions involving multiple nodes. For simplicity, here we consider the following two settings: Multiplex : This is a set \\(\\{G_i\\}\\) of \\(m\\) graphs \\(G_i=(V,E_i)\\) \\(i=1,\\dots,m\\) , the layers , each defined on the same set of nodes but with possibly different edge sets Hypergraph : Just like a standard graph, this is a pair \\(H=(V,\\mathcal E)\\) where the set of hyperedges \\(\\mathcal E\\) is such that each \\(e\\in \\mathcal E\\) can involve an arbitrary number of nodes, rather than just two nodes as in the standard graph case. Node and layer eigenvector centrality for multiplex A multiplex network \\(\\{G_k\\}\\) can be naturally described by means of an adjacency tensor \\(\\mathcal A\\) with three modes \\[ \\mathcal A_{ijk} = \\begin{cases} \\omega_k(ij) & i\\to j \\text{ on layer }k \\\\ 0 & \\text{otherwise} \\end{cases} \\] where \\(\\omega_k:E_k\\to \\mathbb R_{>0}\\) is a positive weight function for the edges of the \\(k\\) -th layer and \\(i\\to j\\) means that there is an edge from node \\(i\\) to node \\(j\\) , i.e. \\(i,j\\in E_k\\) . How can we define a mutual reinforcing centrality score for nodes (and layers) in \\(\\{G_k\\}\\) so that a larger centrality is assigned to nodes that form links in highly influential layers with other central nodes? Here we discuss the model proposed in 5 based on \\(\\mathcal A\\) and a multihomogeneous order-preserving mapping associated to it. Other approaches are discussed in #Related work . In this model, mutual reinforcement happens at both layer and node levels, as layers are more influential if highly central nodes are active in them. Thus, if \\(x_i\\) denotes the centrality of node \\(i\\) and \\(y_k\\) the influence of layer \\(k\\) , we require that \\[\\begin{equation}\\label{eq:tensor_singvec} \\left\\{ \\begin{array}{l} \\sum_{j,k}\\mathcal A_{i,j,k}x_jy_k = \\lambda \\, |x_i|^{p} \\mathrm{sign}(x_i)\\\\[.5em] \\sum_{i,j}\\mathcal A_{i,j,k}x_ix_j = \\mu\\, |y_k|^{q} \\mathrm{sign}(y_k) \\end{array} \\right. \\end{equation}\\] which imposes that a power of the importance of node \\(i\\) is proportional to the sum of the importances of the nodes that point at \\(i\\) , times the influence of the layer where such connections take place and, similarly, defines the \\(q\\) -power of the influence of the layer \\(k\\) as being proportional the product of the centrality of the nodes that are connected in that layer. Since the centrality score is a positive number this is equivalent to Related work Extending eigenvector centrality to higher-order graph models is nontrivial as it first requires extending standard one-dimensional graph mappings, then generalizing mutual-reinforcing properties via suitable eigenequations and finally providing the supporting mathematics for their well-posedeness and computation. A relatively standard way to extend graph mappings and their eigenvectors to the higher-order setting is via a \u201cflattening\u201d or a \u201cprojection\u201d. These are forms of linearizations where the whole higher-order graph is flattened into a standard graph to which standard centrality models are applied. There are many approaches that follow this line, including linear-weighted clique expansions \\cite{carletti2020random,rodri2002laplacian,rodriguez2003laplacian,rodriguez2009laplacian,agarwal2006higher,zhou2007hypergraph}, where hyperedges are replaced by cliques in the flattened graph, whose adjacency matrix becomes \\[\\begin{equation}\\label{eq:clique-expansion-adjacency} A_{ij} = \\sum_{e: \\, i,j\\in e}w(e) \\end{equation}\\] with \\(w(e)\\) the weights of the original hypergraph; clique averaging \\cite{agarwal2005beyond} , where the weights \\(w(e)\\) in the sum \\(\\eqref{eq:clique-expansion-adjacency}\\) are averaged with generalized mean functions; connectivity graph expansion \\cite{banerjee2021spectrum,de2021phase}, where the weights in the clique expansion are based on hyperedge degrees, for example replacing \\(w(e)\\) with \\(1/(|e|-1)\\) in \\eqref{eq:clique-expansion-adjacency}; the star expansion \\cite{zien1999multilevel}, where the flattened graph is obtained by introducing new vertices for each hyperedge, which are then connected according to the hypergraph structure; Node and edge eigenvector centrality for hypergraphs Related work tensor Unlike flattening models, tensor-based approaches maintain the higher-order structure of the network. Spectral methods for tensor-based mappings have seen a great growth in recent years \\cite{li2013z,ng2010finding,hu2013cored,chen2017fiedler,qi2017tensor} and are based on different notions of tensor eigenvectors. In the non-dyadic setting, tensor-based centrality scores for the nodes of a \\(k\\) -uniform hypergraph are defined in e.g.\\ \\cite{benson2019three,ng2011multirank,zhou2007co,deng2009generalized}. % in terms of tensor eigenvectors. As every hyperedge contains exactly \\(k\\) nodes, we can associate to the hypergraph the adjacency tensor \\(\\mathcal A\\) such that \\(\\mathcal A_{i_1,\\dots,i_k} = w(e)\\) if the hyperedge \\(e = \\{i_1,\\dots,i_k\\}\\) is in the hypergraph, and \\(\\mathcal A_{i_1,\\dots,i_k}=0\\) otherwise. %Clearly, \\(\\mathcal A\\) coincides with the adjacency matrix of the graph when \\(k=2\\) . The %tensor-eigenvector centrality score \\(x\\) for the nodes of the hypergraph is then defined via the constrained tensor eigenvector equation % Different notions of tensor eigenvectors are available in the literature (see e.g., % \\cite{cipolla2019shifted,gautier2019unifying}). In particular, for \\(p>1\\) , a \\(\\ell^p\\) eigenvector for \\(\\mathcal A\\) is a vector \\(x\\) such that \\[\\begin{equation}\\label{eq:tensor_eig} \\sum_{i_2,\\dots,i_k}\\mathcal A_{i_1,i_2,\\dots,i_k}x_{i_2}x_{i_3}\\cdots x_{i_k} = \\lambda \\, |x_{i_1}|^{p-2}x_{i_1} \\end{equation}\\] with \\(x>0\\) , \\(\\lambda>0\\) and \\(p>1\\) . %The special cases \\(p=2\\) and \\(p={k}\\) correspond to so-called \\(Z\\) - and \\(H\\) -eigenvectors for \\(\\mathcal A\\) . %A centrality for the nodes of \\(H\\) is a solution \\(x\\) to \\eqref{eq:tensor_eig} such that \\(x>0\\) and \\(\\lambda>0\\) . J. P. Sch\u00e4fermeyer. On Edmund Landau\u2019s contribution to the ranking of chess players. Technical Report, Unpublished manuscript, 2019. \u21a9 P. Bonacich. Power and centrality: a family of measures. American Journal of Sociology , 92:1170\u20131182, 1987. \u21a9 Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The PageRank citation ranking: Bringing order to the web. Technical Report, Stanford InfoLab, 1999. \u21a9 Jon M Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM \\(JACM\\) , 46 \\(5\\) :604\u2013632, 1999. \u21a9 Francesco Tudisco, Francesca Arrigo, and Antoine Gautier. Node and layer eigenvector centralities for multiplex networks. SIAM Journal on Applied Mathematics , 78 \\(2\\) :853\u2013876, 2018. \u21a9","title":"Centrality"},{"location":"centrality/#network_centrality","text":"Ranking the nodes of a network according to suitable \u201ccentrality measures\u201d is a recurring and fundamental question in network science and data mining. Among the various network centrality models, the class of eigenvector centrality is one of the most widely used and effective. This family of models dates back to chess tournaments in the 19th Century by Edmund Landau 1 and was then popularized in the network science community starting from the late \u201980s with Bonacich 2 , PageRank 3 and HITS 4 models. This class of scores assigns importances are based on the leading eigenvector \\(x\\) (or the leading singular vectors \\(x,y\\) ) of suitable network matrices and strongly rely on the matrix Perron-Frobenius theorem. One of the keys of the success of eigenvector centralities is that they naturally incorporate mutual reinforcement : important objects are those that interact with many other important objects. For example, when \\(G=(V,E)\\) is a graph with adjacency matrix \\(A\\) , Bonacich centrality model defines the importance \\(x_i\\) of node \\(i\\in V\\) as \\[ x_i\\propto \\sum_{j: \\, ij\\in E} A_{ij} \\, x_j\\, , \\] that is, the importance of node \\(x_i\\) is linearly proportional to the importances \\(x_j\\) of the nodes it shares an edge with. The Perron-Frobenius theory teaches us that only one such vector \\(x\\) exists: the Perron eigenvector of the adjacency matrix \\(Ax=\\rho(A)x\\) .","title":"Network centrality"},{"location":"centrality/#higher-order_network_models","text":"While graph and networks are ubiquitous in the natural sciences, in many real-world applications we are confronted with higher-order interaction data. Relational data is full of interactions that happen in groups. For example, friendship relations very often happen in groups that are strictly larger than two individuals. Moreover, interactions naturally occur on multiple layers, for example work relations, sport relations, friendship relations, etc. To model higher-order interactions we need higher-order network models, which include multilayer networks , where we have a set of networks (so-called layers) with connections internally and across the layers, and non-dyadic networks , such as hypergraphs or simplicial complexes, where we have access to interactions involving multiple nodes. For simplicity, here we consider the following two settings: Multiplex : This is a set \\(\\{G_i\\}\\) of \\(m\\) graphs \\(G_i=(V,E_i)\\) \\(i=1,\\dots,m\\) , the layers , each defined on the same set of nodes but with possibly different edge sets Hypergraph : Just like a standard graph, this is a pair \\(H=(V,\\mathcal E)\\) where the set of hyperedges \\(\\mathcal E\\) is such that each \\(e\\in \\mathcal E\\) can involve an arbitrary number of nodes, rather than just two nodes as in the standard graph case.","title":"Higher-order network models"},{"location":"centrality/#node_and_layer_eigenvector_centrality_for_multiplex","text":"A multiplex network \\(\\{G_k\\}\\) can be naturally described by means of an adjacency tensor \\(\\mathcal A\\) with three modes \\[ \\mathcal A_{ijk} = \\begin{cases} \\omega_k(ij) & i\\to j \\text{ on layer }k \\\\ 0 & \\text{otherwise} \\end{cases} \\] where \\(\\omega_k:E_k\\to \\mathbb R_{>0}\\) is a positive weight function for the edges of the \\(k\\) -th layer and \\(i\\to j\\) means that there is an edge from node \\(i\\) to node \\(j\\) , i.e. \\(i,j\\in E_k\\) . How can we define a mutual reinforcing centrality score for nodes (and layers) in \\(\\{G_k\\}\\) so that a larger centrality is assigned to nodes that form links in highly influential layers with other central nodes? Here we discuss the model proposed in 5 based on \\(\\mathcal A\\) and a multihomogeneous order-preserving mapping associated to it. Other approaches are discussed in #Related work . In this model, mutual reinforcement happens at both layer and node levels, as layers are more influential if highly central nodes are active in them. Thus, if \\(x_i\\) denotes the centrality of node \\(i\\) and \\(y_k\\) the influence of layer \\(k\\) , we require that \\[\\begin{equation}\\label{eq:tensor_singvec} \\left\\{ \\begin{array}{l} \\sum_{j,k}\\mathcal A_{i,j,k}x_jy_k = \\lambda \\, |x_i|^{p} \\mathrm{sign}(x_i)\\\\[.5em] \\sum_{i,j}\\mathcal A_{i,j,k}x_ix_j = \\mu\\, |y_k|^{q} \\mathrm{sign}(y_k) \\end{array} \\right. \\end{equation}\\] which imposes that a power of the importance of node \\(i\\) is proportional to the sum of the importances of the nodes that point at \\(i\\) , times the influence of the layer where such connections take place and, similarly, defines the \\(q\\) -power of the influence of the layer \\(k\\) as being proportional the product of the centrality of the nodes that are connected in that layer. Since the centrality score is a positive number this is equivalent to","title":"Node and layer eigenvector centrality for multiplex"},{"location":"centrality/#related_work","text":"Extending eigenvector centrality to higher-order graph models is nontrivial as it first requires extending standard one-dimensional graph mappings, then generalizing mutual-reinforcing properties via suitable eigenequations and finally providing the supporting mathematics for their well-posedeness and computation. A relatively standard way to extend graph mappings and their eigenvectors to the higher-order setting is via a \u201cflattening\u201d or a \u201cprojection\u201d. These are forms of linearizations where the whole higher-order graph is flattened into a standard graph to which standard centrality models are applied. There are many approaches that follow this line, including linear-weighted clique expansions \\cite{carletti2020random,rodri2002laplacian,rodriguez2003laplacian,rodriguez2009laplacian,agarwal2006higher,zhou2007hypergraph}, where hyperedges are replaced by cliques in the flattened graph, whose adjacency matrix becomes \\[\\begin{equation}\\label{eq:clique-expansion-adjacency} A_{ij} = \\sum_{e: \\, i,j\\in e}w(e) \\end{equation}\\] with \\(w(e)\\) the weights of the original hypergraph; clique averaging \\cite{agarwal2005beyond} , where the weights \\(w(e)\\) in the sum \\(\\eqref{eq:clique-expansion-adjacency}\\) are averaged with generalized mean functions; connectivity graph expansion \\cite{banerjee2021spectrum,de2021phase}, where the weights in the clique expansion are based on hyperedge degrees, for example replacing \\(w(e)\\) with \\(1/(|e|-1)\\) in \\eqref{eq:clique-expansion-adjacency}; the star expansion \\cite{zien1999multilevel}, where the flattened graph is obtained by introducing new vertices for each hyperedge, which are then connected according to the hypergraph structure;","title":"Related work"},{"location":"centrality/#node_and_edge_eigenvector_centrality_for_hypergraphs","text":"","title":"Node and edge eigenvector centrality for hypergraphs"},{"location":"centrality/#related_work_tensor","text":"Unlike flattening models, tensor-based approaches maintain the higher-order structure of the network. Spectral methods for tensor-based mappings have seen a great growth in recent years \\cite{li2013z,ng2010finding,hu2013cored,chen2017fiedler,qi2017tensor} and are based on different notions of tensor eigenvectors. In the non-dyadic setting, tensor-based centrality scores for the nodes of a \\(k\\) -uniform hypergraph are defined in e.g.\\ \\cite{benson2019three,ng2011multirank,zhou2007co,deng2009generalized}. % in terms of tensor eigenvectors. As every hyperedge contains exactly \\(k\\) nodes, we can associate to the hypergraph the adjacency tensor \\(\\mathcal A\\) such that \\(\\mathcal A_{i_1,\\dots,i_k} = w(e)\\) if the hyperedge \\(e = \\{i_1,\\dots,i_k\\}\\) is in the hypergraph, and \\(\\mathcal A_{i_1,\\dots,i_k}=0\\) otherwise. %Clearly, \\(\\mathcal A\\) coincides with the adjacency matrix of the graph when \\(k=2\\) . The %tensor-eigenvector centrality score \\(x\\) for the nodes of the hypergraph is then defined via the constrained tensor eigenvector equation % Different notions of tensor eigenvectors are available in the literature (see e.g., % \\cite{cipolla2019shifted,gautier2019unifying}). In particular, for \\(p>1\\) , a \\(\\ell^p\\) eigenvector for \\(\\mathcal A\\) is a vector \\(x\\) such that \\[\\begin{equation}\\label{eq:tensor_eig} \\sum_{i_2,\\dots,i_k}\\mathcal A_{i_1,i_2,\\dots,i_k}x_{i_2}x_{i_3}\\cdots x_{i_k} = \\lambda \\, |x_{i_1}|^{p-2}x_{i_1} \\end{equation}\\] with \\(x>0\\) , \\(\\lambda>0\\) and \\(p>1\\) . %The special cases \\(p=2\\) and \\(p={k}\\) correspond to so-called \\(Z\\) - and \\(H\\) -eigenvectors for \\(\\mathcal A\\) . %A centrality for the nodes of \\(H\\) is a solution \\(x\\) to \\eqref{eq:tensor_eig} such that \\(x>0\\) and \\(\\lambda>0\\) . J. P. Sch\u00e4fermeyer. On Edmund Landau\u2019s contribution to the ranking of chess players. Technical Report, Unpublished manuscript, 2019. \u21a9 P. Bonacich. Power and centrality: a family of measures. American Journal of Sociology , 92:1170\u20131182, 1987. \u21a9 Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The PageRank citation ranking: Bringing order to the web. Technical Report, Stanford InfoLab, 1999. \u21a9 Jon M Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM \\(JACM\\) , 46 \\(5\\) :604\u2013632, 1999. \u21a9 Francesco Tudisco, Francesca Arrigo, and Antoine Gautier. Node and layer eigenvector centralities for multiplex networks. SIAM Journal on Applied Mathematics , 78 \\(2\\) :853\u2013876, 2018. \u21a9","title":"Related work tensor"},{"location":"chapter1/","text":"The Perron-Frobenius theorem for multihomogeneous mappings The cone of nonnegative vectors The Perron-Frobenius theory deals with operators that leave a normal, convex and pointed cone invariant. The cone of nonnegative vectors is the most common example of such a cone and the one that most often arises in applications. We denote such cone as \\(C_+ \\subseteq \\mathbb R^n\\) or, when the dimension is clear from the context, simply as \\(C_+.\\) The elements of \\(C_+\\) are vectors whose components are all nonnegative. Whereas the interior \\(C_{++}\\) of \\(C_+\\) is the set of entrywise positive vectors: \\(C_+ = \\{x\\in \\mathbb R^n : x_i\\geq 0\\) for all \\(i=1,\\dots,n\\}=\\{x\\in \\mathbb R^n : x\\succeq 0\\}\\) \\(C_{++} = \\{x\\in \\mathbb R^n : x_i> 0\\) for all \\(i=1,\\dots,n\\}=\\{x\\in \\mathbb R^n : x\\succ 0\\}.\\) \\(C_+\\) is convex, pointed and normal as \\(\\alpha x\\in C_+\\) for all \\(x\\in C_+\\) and all scalar coefficients \\(\\alpha \\geq 0\\) , \\(C_+\\cap -C_+ = \\{0\\}\\) and for all pair of vectors \\(x,y\\in C_+\\) such that \\(x\\preceq y\\) there exists a \\(\\gamma>0\\) such that \\(\\|x\\|\\leq \\gamma \\|y\\|\\) . Here \\(\\|\\cdot\\|\\) is any norm on \\(\\mathbb R^n\\) . This tutorial will focus only on \\(C_+\\) however, however we point out that all the results we will present can be relatively directly transferred to arbitrary normal, convex and pointed cones. Hilbert projective distance One of the key tools for the Perron-Frobenius theory for nonlinear mappings is the Hilbert distance. For any two positive vectors \\(x,y\\succ 0\\) , this is defined as: 1 \\[d_H(x,y) = \\ln\\Big(\\max_{i=1,\\dots,n}\\frac{x_i}{y_i}\\max_{i=1,\\dots,n}\\frac{y_i}{x_i}\\Big)\\] \\(d_H\\) is a metric on the space of rays in \\(C_{++}\\) , that is it holds 2 \\(d_H(\\alpha x, \\beta y) =d_H(x,y)\\) for all scalar coefficients \\(\\alpha,\\beta >0\\) ds Lorem markdownum fuit peragit eunti, cum illuc heu ferrumque gentis. Curvarique loca remoraminaque terram iniustaque tempora luctusque vitam; tela iunxit gratia fontibus ut tempus cupiasque relevasse altis. Mutantur carpere geratis Scorpius. Visa ego delendaque, victae esse pervenit et arentia gentem. if (5 + net) { alignment = jumperPpi; ppl_server = multiplatform(2, -1) + switchCable; } var integerCarrier = uml_p_tween; metafileCdPram -= scareware.barMultiprocessingIo.box(fiber, plugSyn.integrated_add(gif, camera, export_vga_multithreading)); if (processorSdk) { taskCcd = client_clipboard_syntax; } Prope sine coepta: reddi tabo virens expositum amaris saxo medio fons esse Nisi. Dixit dolorem simulamina motus. Gradibus tuta quae addere vero iuvenis candida; ictu Phocaico, tempore addicere pluma terra? Est deus pericula exigere figit Iani rumpere raptos o columbae non et leonis ferre qui quinque arva idem dixit haec; advertite candore. Mora invitusque casses, totidemque et erat in nonne novat iamque: quae? Ab nec fecit et idonea nunc lumine Spartana nunc vertice brevis pendebant levius contraria aere? Iram orba ferarum dei eburnea; voce praestantes, me squamas victor contigit pia! pitch_ecc.serp_clip = -5 + -1; box.tape_digital(subnet_only); esports_query_multiprocessing.fontPiconetServices -= document_laptop; Ipse nomen, certum ego; heros nam, donec et semper parenti formatae si iuvenum. Insidias dextera anumque est habitandae nubes. Quo Latina, quidem: positisque, inter regia puer iurgia, illa illos ille limine flammifera dracones et. Retenta Metione atque iam quoque Iunone pabula. Canna ora maxima non penates cautum cruorem quid quid falsi. Ara plus templa, nymphe innato parum vestrae , tunc caput instat quo. Tum moras si Euagrus freta ferrove urbs nec etiam ipsis. Nunc quod aut intrarunt et graves urbes, telluris carmen coget corpus. This definition is strictly related to the choice of the nonnegative cone \\(C_+\\) . For general cones, the definition of \\(d_H\\) changes. However, all its properties do not change. \u21a9 Lemmens, Nussbaum, Citation test \u21a9","title":"Chapter1"},{"location":"chapter1/#the_perron-frobenius_theorem_for_multihomogeneous_mappings","text":"","title":"The Perron-Frobenius theorem for multihomogeneous mappings"},{"location":"chapter1/#the_cone_of_nonnegative_vectors","text":"The Perron-Frobenius theory deals with operators that leave a normal, convex and pointed cone invariant. The cone of nonnegative vectors is the most common example of such a cone and the one that most often arises in applications. We denote such cone as \\(C_+ \\subseteq \\mathbb R^n\\) or, when the dimension is clear from the context, simply as \\(C_+.\\) The elements of \\(C_+\\) are vectors whose components are all nonnegative. Whereas the interior \\(C_{++}\\) of \\(C_+\\) is the set of entrywise positive vectors: \\(C_+ = \\{x\\in \\mathbb R^n : x_i\\geq 0\\) for all \\(i=1,\\dots,n\\}=\\{x\\in \\mathbb R^n : x\\succeq 0\\}\\) \\(C_{++} = \\{x\\in \\mathbb R^n : x_i> 0\\) for all \\(i=1,\\dots,n\\}=\\{x\\in \\mathbb R^n : x\\succ 0\\}.\\) \\(C_+\\) is convex, pointed and normal as \\(\\alpha x\\in C_+\\) for all \\(x\\in C_+\\) and all scalar coefficients \\(\\alpha \\geq 0\\) , \\(C_+\\cap -C_+ = \\{0\\}\\) and for all pair of vectors \\(x,y\\in C_+\\) such that \\(x\\preceq y\\) there exists a \\(\\gamma>0\\) such that \\(\\|x\\|\\leq \\gamma \\|y\\|\\) . Here \\(\\|\\cdot\\|\\) is any norm on \\(\\mathbb R^n\\) . This tutorial will focus only on \\(C_+\\) however, however we point out that all the results we will present can be relatively directly transferred to arbitrary normal, convex and pointed cones.","title":"The cone of nonnegative vectors"},{"location":"chapter1/#hilbert_projective_distance","text":"One of the key tools for the Perron-Frobenius theory for nonlinear mappings is the Hilbert distance. For any two positive vectors \\(x,y\\succ 0\\) , this is defined as: 1 \\[d_H(x,y) = \\ln\\Big(\\max_{i=1,\\dots,n}\\frac{x_i}{y_i}\\max_{i=1,\\dots,n}\\frac{y_i}{x_i}\\Big)\\] \\(d_H\\) is a metric on the space of rays in \\(C_{++}\\) , that is it holds 2 \\(d_H(\\alpha x, \\beta y) =d_H(x,y)\\) for all scalar coefficients \\(\\alpha,\\beta >0\\) ds Lorem markdownum fuit peragit eunti, cum illuc heu ferrumque gentis. Curvarique loca remoraminaque terram iniustaque tempora luctusque vitam; tela iunxit gratia fontibus ut tempus cupiasque relevasse altis. Mutantur carpere geratis Scorpius. Visa ego delendaque, victae esse pervenit et arentia gentem. if (5 + net) { alignment = jumperPpi; ppl_server = multiplatform(2, -1) + switchCable; } var integerCarrier = uml_p_tween; metafileCdPram -= scareware.barMultiprocessingIo.box(fiber, plugSyn.integrated_add(gif, camera, export_vga_multithreading)); if (processorSdk) { taskCcd = client_clipboard_syntax; } Prope sine coepta: reddi tabo virens expositum amaris saxo medio fons esse Nisi. Dixit dolorem simulamina motus. Gradibus tuta quae addere vero iuvenis candida; ictu Phocaico, tempore addicere pluma terra?","title":"Hilbert projective distance"},{"location":"chapter1/#est_deus_pericula_exigere_figit","text":"Iani rumpere raptos o columbae non et leonis ferre qui quinque arva idem dixit haec; advertite candore. Mora invitusque casses, totidemque et erat in nonne novat iamque: quae? Ab nec fecit et idonea nunc lumine Spartana nunc vertice brevis pendebant levius contraria aere? Iram orba ferarum dei eburnea; voce praestantes, me squamas victor contigit pia! pitch_ecc.serp_clip = -5 + -1; box.tape_digital(subnet_only); esports_query_multiprocessing.fontPiconetServices -= document_laptop; Ipse nomen, certum ego; heros nam, donec et semper parenti formatae si iuvenum. Insidias dextera anumque est habitandae nubes. Quo Latina, quidem: positisque, inter regia puer iurgia, illa illos ille limine flammifera dracones et. Retenta Metione atque iam quoque Iunone pabula. Canna ora maxima non penates cautum cruorem quid quid falsi. Ara plus templa, nymphe innato parum vestrae , tunc caput instat quo. Tum moras si Euagrus freta ferrove urbs nec etiam ipsis. Nunc quod aut intrarunt et graves urbes, telluris carmen coget corpus. This definition is strictly related to the choice of the nonnegative cone \\(C_+\\) . For general cones, the definition of \\(d_H\\) changes. However, all its properties do not change. \u21a9 Lemmens, Nussbaum, Citation test \u21a9","title":"Est deus pericula exigere figit"},{"location":"chapter3/","text":"Node and layer eigenvector centrality for multiplex A multiplex network \\(\\{G_k\\}\\) can be naturally described by means of an adjacency tensor \\(\\mathcal A\\) with three modes \\[ \\mathcal A_{ijk} = \\begin{cases} \\omega_k(ij) & i\\to j \\text{ on layer }k \\\\ 0 & \\text{otherwise} \\end{cases} \\] where \\(\\omega_k:E_k\\to \\RR_{++}\\) is a positive weight function for the edges of the \\(k\\) -th layer and \\(i\\to j\\) means that there is an edge from node \\(i\\) to node \\(j\\) , i.e. \\(i,j\\in E_k\\) . How can we define a mutual reinforcing centrality score for nodes (and layers) in \\(\\{G_k\\}\\) so that a larger centrality is assigned to nodes that form links in highly influential layers with other central nodes? Here we discuss the model proposed in 1 based on \\(\\mathcal A\\) and a multihomogeneous order-preserving mapping associated to it. Other approaches are discussed briefly in Related work . In this model, mutual reinforcement happens at both layer and node levels, as layers are more influential if highly central nodes are active in them. Thus, if \\(x_i\\) denotes the centrality of node \\(i\\) and \\(y_k\\) the influence of layer \\(k\\) , we require that \\(x_i \\propto \\sum_{jk}\\mathcal A_{ijk}x_jy_k\\) , and \\(y_k \\propto \\sum_{ij}\\mathcal A_{ijk}x_ix_j\\) Since the centrality score is Related work Extending eigenvector centrality to higher-order graph models is nontrivial as it first requires extending standard one-dimensional graph mappings, then generalizing mutual-reinforcing properties via suitable eigenequations and finally providing the supporting mathematics for their well-posedeness and computation. A relatively standard way to extend graph mappings and their eigenvectors to the higher-order setting is via a \u201cflattening\u201d or a \u201cprojection\u201d. These are forms of linearizations where the whole higher-order graph is flattened into a standard graph to which standard centrality models are applied. There are many approaches that follow this line, including linear-weighted clique expansions \\cite{carletti2020random,rodri2002laplacian,rodriguez2003laplacian,rodriguez2009laplacian,agarwal2006higher,zhou2007hypergraph}, where hyperedges are replaced by cliques in the flattened graph, whose adjacency matrix becomes \\[\\begin{equation}\\label{eq:clique-expansion-adjacency} A_{ij} = \\sum_{e: \\, i,j\\in e}w(e) \\end{equation}\\] with \\(w(e)\\) the weights of the original hypergraph; clique averaging \\cite{agarwal2005beyond}, where the weights \\(w(e)\\) in the sum \\eqref{eq:clique-expansion-adjacency} are averaged with generalized mean functions; connectivity graph expansion \\cite{banerjee2021spectrum,de2021phase}, where the weights in the clique expansion are based on hyperedge degrees, for example replacing \\(w(e)\\) with \\(1/(|e|-1)\\) in \\eqref{eq:clique-expansion-adjacency}; the star expansion \\cite{zien1999multilevel}, where the flattened graph is obtained by introducing new vertices for each hyperedge, which are then connected according to the hypergraph structure; Francesco Tudisco, Francesca Arrigo, and Antoine Gautier. Node and layer eigenvector centralities for multiplex networks. SIAM Journal on Applied Mathematics , 78 \\(2\\) :853\u2013876, 2018. \u21a9","title":"Chapter3"},{"location":"chapter3/#node_and_layer_eigenvector_centrality_for_multiplex","text":"A multiplex network \\(\\{G_k\\}\\) can be naturally described by means of an adjacency tensor \\(\\mathcal A\\) with three modes \\[ \\mathcal A_{ijk} = \\begin{cases} \\omega_k(ij) & i\\to j \\text{ on layer }k \\\\ 0 & \\text{otherwise} \\end{cases} \\] where \\(\\omega_k:E_k\\to \\RR_{++}\\) is a positive weight function for the edges of the \\(k\\) -th layer and \\(i\\to j\\) means that there is an edge from node \\(i\\) to node \\(j\\) , i.e. \\(i,j\\in E_k\\) . How can we define a mutual reinforcing centrality score for nodes (and layers) in \\(\\{G_k\\}\\) so that a larger centrality is assigned to nodes that form links in highly influential layers with other central nodes? Here we discuss the model proposed in 1 based on \\(\\mathcal A\\) and a multihomogeneous order-preserving mapping associated to it. Other approaches are discussed briefly in Related work . In this model, mutual reinforcement happens at both layer and node levels, as layers are more influential if highly central nodes are active in them. Thus, if \\(x_i\\) denotes the centrality of node \\(i\\) and \\(y_k\\) the influence of layer \\(k\\) , we require that \\(x_i \\propto \\sum_{jk}\\mathcal A_{ijk}x_jy_k\\) , and \\(y_k \\propto \\sum_{ij}\\mathcal A_{ijk}x_ix_j\\) Since the centrality score is","title":"Node and layer eigenvector centrality for multiplex"},{"location":"chapter3/#related_work","text":"Extending eigenvector centrality to higher-order graph models is nontrivial as it first requires extending standard one-dimensional graph mappings, then generalizing mutual-reinforcing properties via suitable eigenequations and finally providing the supporting mathematics for their well-posedeness and computation. A relatively standard way to extend graph mappings and their eigenvectors to the higher-order setting is via a \u201cflattening\u201d or a \u201cprojection\u201d. These are forms of linearizations where the whole higher-order graph is flattened into a standard graph to which standard centrality models are applied. There are many approaches that follow this line, including linear-weighted clique expansions \\cite{carletti2020random,rodri2002laplacian,rodriguez2003laplacian,rodriguez2009laplacian,agarwal2006higher,zhou2007hypergraph}, where hyperedges are replaced by cliques in the flattened graph, whose adjacency matrix becomes \\[\\begin{equation}\\label{eq:clique-expansion-adjacency} A_{ij} = \\sum_{e: \\, i,j\\in e}w(e) \\end{equation}\\] with \\(w(e)\\) the weights of the original hypergraph; clique averaging \\cite{agarwal2005beyond}, where the weights \\(w(e)\\) in the sum \\eqref{eq:clique-expansion-adjacency} are averaged with generalized mean functions; connectivity graph expansion \\cite{banerjee2021spectrum,de2021phase}, where the weights in the clique expansion are based on hyperedge degrees, for example replacing \\(w(e)\\) with \\(1/(|e|-1)\\) in \\eqref{eq:clique-expansion-adjacency}; the star expansion \\cite{zien1999multilevel}, where the flattened graph is obtained by introducing new vertices for each hyperedge, which are then connected according to the hypergraph structure; Francesco Tudisco, Francesca Arrigo, and Antoine Gautier. Node and layer eigenvector centralities for multiplex networks. SIAM Journal on Applied Mathematics , 78 \\(2\\) :853\u2013876, 2018. \u21a9","title":"Related work"}]}